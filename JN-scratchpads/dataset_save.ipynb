{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg2\n",
    "import secrets_jenny\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = secrets_jenny.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=secrets['db_url'],\n",
    "        port=secrets['port'],\n",
    "        dbname=secrets['db_name'],\n",
    "        user=secrets['username'],\n",
    "        password=secrets['password'],\n",
    "        connect_timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "select\n",
    "state_fips,\n",
    "year,\n",
    "corp_income_tax_low,\n",
    "corp_income_tax_high\n",
    " \n",
    "from state_corp_income_tax_long\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "corp = pd.read_sql(query1, con=conn)\n",
    "\n",
    "# State Corporate Income tax - long version\n",
    "query2 = \"\"\"\n",
    "select\n",
    "state_fips,\n",
    "year,\n",
    "income_tax_low,\n",
    "income_tax_high\n",
    "from state_income_tax_long\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "tax = pd.read_sql(query2, con=conn)\n",
    "\n",
    "# County Debt ratio - long version\n",
    "query3 = \"\"\"\n",
    "select * \n",
    "from county_debt_ratio_long\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "debt = pd.read_sql(query3, con=conn)\n",
    "\n",
    "# County vehicles - long version\n",
    "query4 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "vehicles_per_person\n",
    "\n",
    "from acs1_vehicles_available\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "vehicles = pd.read_sql(query4, con=conn)\n",
    "\n",
    "# County travel_time- long version\n",
    "query5 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "travel_time_to_work\n",
    "\n",
    "from acs1_travel_time_to_work\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "travel = pd.read_sql(query5, con=conn)\n",
    "\n",
    "\n",
    "# County population- long version\n",
    "query6 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "population\n",
    "\n",
    "from acs1_population\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "population = pd.read_sql(query6, con=conn)\n",
    "\n",
    "# County household income- long version\n",
    "query7 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "household_income\n",
    "\n",
    "from acs1_household_income\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "income = pd.read_sql(query7, con=conn)\n",
    "\n",
    "# County Median Home value- long version\n",
    "query8 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "home_value_median\n",
    "\n",
    "from acs1_home_value_median\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "home_value = pd.read_sql(query8, con=conn)\n",
    "\n",
    "# County births by age\n",
    "query9 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "birth_15_19_pct,\n",
    "birth_20_24_pct,\n",
    "birth_25_29_pct,\n",
    "birth_30_34_pct,\n",
    "birth_35_39_pct,\n",
    "birth_40_44_pct,\n",
    "birth_45_50_pct\n",
    "\n",
    "from acs1_births_by_age\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "births = pd.read_sql(query9, con=conn)\n",
    "\n",
    "# County educational attainment\n",
    "query10 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "grade12_nodiploma_pct,\n",
    "hs_diploma_pct,\n",
    "some_college_lessthan_1yr_pct,\n",
    "some_college_greaterthan_1yr_pct,\n",
    "bachelor_degree_pct,\n",
    "master_degree_pct,\n",
    "professional_degree_pct,\n",
    "doctorate_degree_pct\n",
    "\n",
    "from acs1_educational_attainment\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "education = pd.read_sql(query10, con=conn)\n",
    "\n",
    "# County occupancy\n",
    "query11 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "occupied_units_pct,\n",
    "vacant_units_pct\n",
    "\n",
    "from acs1_occupancy\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "occupancy = pd.read_sql(query11, con=conn)\n",
    "\n",
    "# County rent\n",
    "query12 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "rent_1bed_median,\n",
    "rent_2bed_median,\n",
    "rent_3bed_median,\n",
    "rent_4bed_median\n",
    "\n",
    "from acs1_rent\n",
    "\"\"\"\n",
    "\n",
    "rent = pd.read_sql(query12, con=conn)\n",
    "\n",
    "# County wage data\n",
    "\n",
    "\n",
    "query13 = \"\"\"\n",
    "select *\n",
    "\n",
    "from \"NEW_bls_wage_by_industry\"\n",
    "where year >= 2014\n",
    "\"\"\"\n",
    "\n",
    "wage = pd.read_sql(query13, con=conn)\n",
    "\n",
    "# query13a = \"\"\"\n",
    "# select *\n",
    "\n",
    "# from bls_wage_by_industry\n",
    "# where year >= 2014\n",
    "# \"\"\"\n",
    "\n",
    "# wage1 = pd.read_sql(query13a, con=conn)\n",
    "\n",
    "# County hpi\n",
    "query14 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "year,\n",
    "annual_change_pct\n",
    "\n",
    "from fhfa_house_price_index\n",
    "\"\"\"\n",
    "\n",
    "hpi = pd.read_sql(query14, con=conn)\n",
    "\n",
    "# County redfin\n",
    "query15 = \"\"\"\n",
    "select \n",
    "county_fips,\n",
    "period_end, \n",
    "property_type, \n",
    "property_type_id, \n",
    "median_sale_price_yoy,\n",
    "median_list_price_yoy, \n",
    "median_ppsf_yoy, \n",
    "median_list_ppsf_yoy, \n",
    "homes_sold_yoy,\n",
    "new_listings_yoy, \n",
    "inventory_yoy, \n",
    "months_of_supply_yoy, \n",
    "median_dom_yoy, \n",
    "avg_sale_to_list_yoy, \n",
    "sold_above_list_yoy\n",
    "\n",
    "\n",
    "\n",
    "from redfin_county_full\n",
    "\n",
    "where property_type ='All Residential'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "redfin = pd.read_sql(query15, con=conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wage = wage.set_index(['year','county_fips'])\n",
    "pay_cols = []\n",
    "emp_cols = []\n",
    "\n",
    "\n",
    "# loop through the columns to get a list of columns for Average Annual Pay (pct change) and Average Annual number of employees\n",
    "for col in wage.columns:\n",
    "    if 'annual_avg_employees' in col:\n",
    "        emp_cols.append(col)\n",
    "    elif 'avg_annual_pay' in col:\n",
    "        if 'pct_chg' not in col:\n",
    "            pay_cols.append(col)\n",
    "\n",
    "\n",
    "# Determine the % change of employees by year, county and industry\n",
    "emp = wage[emp_cols]\n",
    "emp = emp.fillna(0).astype(float)\n",
    "emp = emp.reset_index(level=['year','county_fips'])\n",
    "# convert from wide to long format\n",
    "emp = emp.melt(id_vars=['year','county_fips'],value_name = 'annual_avg_employees')\n",
    "# extract industry code and ownership codes from previous columns\n",
    "emp['naics_industry_code'] = emp['variable'].apply(lambda x: x[:2])\n",
    "emp['owner'] = emp['variable'].apply(lambda x: x[3:4])\n",
    "# as the ownership = 0 is for all ownerships, drop to avoid duplication\n",
    "emp = emp[emp['owner']!='0']\n",
    "# group and total the employees\n",
    "emp = emp.groupby(['year','county_fips','naics_industry_code'], as_index=False)['annual_avg_employees'].sum()\n",
    "emp = emp.sort_values(by=['county_fips','naics_industry_code','year'])\n",
    "# shift total of employees by 1 year to access previous year's total employees and merge back onto employee df\n",
    "prev_emp = emp.groupby(['county_fips','naics_industry_code'])['annual_avg_employees'].shift(1)\n",
    "emp=emp.merge(prev_emp,how='left',left_index=True,right_index=True).rename(\n",
    "    columns={'annual_avg_employees_x':'annual_avg_employees','annual_avg_employees_y':'previous_avg_employee'})\n",
    "# due to absence of 2013 data, set previous year for 2014 to the 2014 value\n",
    "emp['prev_avg_employees'] = emp['previous_avg_employee'].combine_first(emp['annual_avg_employees'])\n",
    "# calculate % change\n",
    "emp['avg_annual_employee_pct_chg'] = ((emp['annual_avg_employees']-emp['prev_avg_employees'])/emp['prev_avg_employees']*100).fillna(0)\n",
    "emp = emp.drop(columns=['previous_avg_employee'])\n",
    "\n",
    "### Repeat for annual pay\n",
    "\n",
    "# Determine the % change in pay by year, county and industry\n",
    "pay = wage[pay_cols]\n",
    "pay = pay.fillna(0).astype(float)\n",
    "pay = pay.reset_index(level=['year','county_fips'])\n",
    "# convert from wide to long format\n",
    "pay = pay.melt(id_vars=['year','county_fips'],value_name = 'annual_avg_pay')\n",
    "# extract industry code and ownership codes from previous columns\n",
    "pay['naics_industry_code'] = pay['variable'].apply(lambda x: x[:2])\n",
    "pay['owner'] = pay['variable'].apply(lambda x: x[3:4])\n",
    "# as the ownership = 0 is for all ownerships, drop to avoid duplication\n",
    "pay = pay[pay['owner']!='0']\n",
    "# group and total the pay\n",
    "pay = pay.groupby(['year','county_fips','naics_industry_code'], as_index=False)['annual_avg_pay'].sum()\n",
    "pay = pay.sort_values(by=['county_fips','naics_industry_code','year'])\n",
    "# shift total  pay by 1 year to access previous year's total pay and merge back onto pay df\n",
    "prev_pay = pay.groupby(['county_fips','naics_industry_code'])['annual_avg_pay'].shift(1)\n",
    "pay=pay.merge(prev_pay,how='left',left_index=True,right_index=True).rename(\n",
    "    columns={'annual_avg_pay_x':'annual_avg_pay','annual_avg_pay_y':'previous_avg_pay'})\n",
    "# due to absence of 2013 data, set previous year for 2014 to the 2014 value\n",
    "pay['prev_avg_pay'] = pay['previous_avg_pay'].combine_first(pay['annual_avg_pay'])\n",
    "# calculate % change\n",
    "pay['avg_annual_pay_pct_chg'] = ((pay['annual_avg_pay']-pay['prev_avg_pay'])/pay['prev_avg_pay']*100).fillna(0)\n",
    "pay = pay.drop(columns=['previous_avg_pay'])\n",
    "\n",
    "# combine emp and pay\n",
    "\n",
    "wages = emp.merge(pay,how='left',on=['year','county_fips','naics_industry_code'])\n",
    "# remove data where there are no employees - we will fill these values with 0 later\n",
    "wages = wages[wages['annual_avg_employees']!=0]\n",
    "# replace inf with 100, representing a 100% change\n",
    "wages = wages.replace([np.inf,-np.inf], 100)\n",
    "# industry code of 10 is a summary code for all industries \n",
    "wages=wages[wages['naics_industry_code']!='10']\n",
    "# keep only percent change columns\n",
    "wages = wages[['year', 'county_fips', 'naics_industry_code','avg_annual_employee_pct_chg','avg_annual_pay_pct_chg']]\n",
    "# pivot to create wide version of dataset\n",
    "wages = wages.pivot_table(index=['year','county_fips'], columns=['naics_industry_code']).fillna(0)\n",
    "wages.columns = [str(a)+'_'+str(b) for b,a in wages.columns]\n",
    "wages = wages.reset_index(['year','county_fips'])\n",
    "\n",
    "#clean up redfin data\n",
    "# Create date columns for filtering.  We will baseline the year over year change using the December records.\n",
    "redfin['date'] = pd.to_datetime(redfin['period_end'])\n",
    "redfin['year'] = redfin['date'].dt.year\n",
    "redfin['month'] = redfin['date'].dt.month\n",
    "redfin = redfin[redfin['month']==12]\n",
    "\n",
    "# find records where all numerical columns are na across the whole row and drop them\n",
    "na_cols = ['median_sale_price_yoy', 'median_list_price_yoy', 'median_ppsf_yoy',\n",
    "       'median_list_ppsf_yoy', 'homes_sold_yoy', 'new_listings_yoy', 'inventory_yoy', 'months_of_supply_yoy',\n",
    "       'median_dom_yoy', 'avg_sale_to_list_yoy', 'sold_above_list_yoy']\n",
    "       \n",
    "\n",
    "na_rows = redfin.index[redfin[na_cols].isnull().all(1)]\n",
    "redfin = redfin.drop(index = na_rows)\n",
    "\n",
    "# Find remaining columns that contain null values \n",
    "for col in redfin.columns:\n",
    "    print(col+':', redfin[col].isnull().sum(), 'null values')\n",
    "\n",
    "redfin.to_csv('redfin.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "redfin = redfin.set_index(['year','county_fips'])\n",
    "redfin_imputed = pd.DataFrame(imputer.fit_transform(redfin[na_cols]), columns=na_cols)\n",
    "redfin_imputed.index=redfin.index\n",
    "redfin_imputed = redfin_imputed.reset_index(['year','county_fips'])\n",
    "#join datasets\n",
    "# debt #1999-2021\n",
    "df = debt.merge(corp,how='left',on=['state_fips','year']) #2014-2022\n",
    "df = df.merge(tax,how='left',on=['state_fips','year']) #2014-2022\n",
    "df = df.merge(wages,how='left',on=['county_fips','year']).fillna(0) #2014-2020\n",
    "df = df.merge(redfin_imputed,how='inner',on=['county_fips','year']) #2012-2021\n",
    "\n",
    "\n",
    "# print(\"Number of unique county fips: \"+str(df.county_fips.nunique()))\n",
    "# for col in df.columns:\n",
    "#     print(col+':', df[col].isnull().sum(), 'null values')\n",
    "\n",
    "df = df.merge(vehicles,how='inner',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(travel,how='left',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(population,how='left',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(income,how='left',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(home_value,how='left',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(births,how='left',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(education,how='left',on=['county_fips','year']) #2014-2019\n",
    "df = df.merge(occupancy,how='left',on=['county_fips','year']) #2014-2019\n",
    "# df = df.merge(rent,how='left',on=['county_fips','year']) #2015-2019\n",
    "\n",
    "# df.county_fips.nunique()\n",
    "# 632\n",
    "\n",
    "# 3606x 78\n",
    "\n",
    "# Plot null values in data\n",
    "\n",
    "# # for prop in df['property_type'].unique():\n",
    "# # temp = df[df['property_type']==prop]\n",
    "# cols = df.set_index(['year','county_fips']).columns[:]    \n",
    "# # cols = df.set_index(['county_fips','year']).columns[:]\n",
    "# colors = ['#000099', '#ffff00']\n",
    "# sns.heatmap(df.sort_values(by=['year','county_fips']).set_index(['year','county_fips'])[cols].isnull(), cmap=sns.color_palette(colors))\n",
    "# # sns.heatmap(df.sort_values(by=['county_fips','year']).set_index(['county_fips','year'])[cols].isnull(), cmap=sns.color_palette(colors))\n",
    "\n",
    "# # plt.title('Property type: '+str(prop))\n",
    "# plt.show()\n",
    "\n",
    "# handle missing values\n",
    "\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed['year'] = df_imputed['year'].astype(int)\n",
    "df_imputed['county_fips'] = df_imputed['county_fips'].astype(int).astype(str)\n",
    "df_imputed['county_fips'] =df_imputed['county_fips'].str.zfill(5) \n",
    "\n",
    "\n",
    "#Bring in HPI target data\n",
    "\n",
    "#reduce year by 1 so that the hpi annual change value is for one year in the future\n",
    "hpi['year'] = hpi['year'].astype(int)\n",
    "hpi['county_fips'] = hpi['county_fips'].astype(str)\n",
    "hpi['year'] = hpi['year'].apply(lambda x: x-1)\n",
    "\n",
    "#merge with indicators and remove nan (not allowed in model)\n",
    "df_imputed = df_imputed.merge(hpi, how='left', on=['year', 'county_fips'])\n",
    "\n",
    "\n",
    "df_imputed['annual_change_pct'] = df_imputed['annual_change_pct'].astype(float)\n",
    "\n",
    "df_imputed = df_imputed.reset_index(drop=True)\n",
    "df_imputed = df_imputed.dropna()\n",
    "\n",
    "\n",
    "# Hold back last year of data set = 2019\n",
    "\n",
    "data = df_imputed[df_imputed['year']!=2019].reset_index(drop=True)\n",
    "d2019 = df_imputed[df_imputed['year']==2019].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data_to2018.pkl')\n",
    "d2019.to_pickle('data_2019.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_to2018.csv')\n",
    "d2019.to_csv('data_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48afe66db347f725036e500dc5f1a42501d7f7e0b12ba873f0d502d0ac62c68b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('capstone_env_v2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
